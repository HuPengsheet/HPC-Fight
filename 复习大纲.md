# 高性能计算求职面试全攻略



# c/c++

### c++内存布局

![image-20240611122949435](/home/hp/code/HPC-Fight/HPC-Fight/image/image-20240611122949435.png)

```
常量区：虚函数表、const修饰的全局变量、字符串常量
程序代码：函数、类函数
全局数据区：全局变量、静态变量
.bss:.主要作用是存放程序中未初始化的全局变量和静态变量。这些变量在编译时没有明确赋初值，因此在程序加载到内存时，系统会自动将.bss段的内存空间清零，以保证变量在使用前具备确定的初值。

```





### c++新特性

#### const与constexpr

```
c++98：const有两个语义，分别是 常量和只读
c++11之后： 
	const:表示只读
	constexpr:表示常量，在编译期会被计算出来
```

#### 

```
灵活性：
    unique_lock比lock_guard更加灵活。它可以实现延时锁定（即先创建unique_lock对象，然后在需要的地方调用lock()函数），而lock_guard在对象创建时就会立即锁定互斥锁。
    unique_lock还可以在需要的时候调用unlock()函数来手动解锁，而lock_guard则只能在对象生命周期结束时自动解锁。

移动性：
    unique_lock是可移动的（movable），这意味着它可以被拷贝、赋值或移动。而lock_guard是不可移动的，它只能通过构造函数初始化和析构函数销毁。

用途：
    由于unique_lock的灵活性，它可以用于更复杂的场景，比如一次性锁定多个互斥锁（通过std::lock函数），或者与条件变量（std::condition_variable）一起使用。而lock_guard则更适用于简单的场景，即只需要在作用域内锁定一个互斥锁。

性能：
    虽然unique_lock提供了更多的功能，但这些功能也带来了性能上的开销。相比之下，lock_guard由于其简单性，通常具有更好的性能。



```





# 操作系统&&计算机体系结构

CPU的基本结构

# 数据结构与算法

### 排序

```c++
void quick_sort(int q[], int l, int r)
{
    if (l >= r) return;

    int i = l - 1, j = r + 1, x = q[l + r >> 1];
    while (i < j)
    {
        do i ++ ; while (q[i] < x);
        do j -- ; while (q[j] > x);
        if (i < j) swap(q[i], q[j]);
    }
    quick_sort(q, l, j), quick_sort(q, j + 1, r);
}

void merge_sort(int q[], int l, int r)
{
    if (l >= r) return;

    int mid = l + r >> 1;
    merge_sort(q, l, mid);
    merge_sort(q, mid + 1, r);

    int k = 0, i = l, j = mid + 1;
    while (i <= mid && j <= r)
        if (q[i] <= q[j]) tmp[k ++ ] = q[i ++ ];
        else tmp[k ++ ] = q[j ++ ];

    while (i <= mid) tmp[k ++ ] = q[i ++ ];
    while (j <= r) tmp[k ++ ] = q[j ++ ];

    for (i = l, j = 0; i <= r; i ++, j ++ ) q[i] = tmp[j];
}

```



### 链表

```
auto low=head;
auto fast=head;

while(fast!=tail&&fast->next!=tail){
    low=low->next;
    fast=fast->next->next;
}
auto mid=low;



right
auto low=head;
auto fast=head;

while(fast!=tail&&fast->next->next!=tail){
    low=low->next;
    fast=fast->next->next;
}
auto mid=low;

```



### 二叉树

### 双指针

### 堆&&栈&&队列

### 回溯

### 动态规划

一般的动态规划问题

背包类问题

```
分类解题模板

背包问题大体的解题模板是两层循环，分别遍历物品nums和背包容量target，然后写转移方程，
根据背包的分类我们确定物品和容量遍历的先后顺序，根据问题的分类我们确定状态转移方程的写法

首先是背包分类的模板：
1、0/1背包：外循环nums,内循环target,target倒序且target>=nums[i];
2、完全背包：外循环nums,内循环target,target正序且target>=nums[i];
3、组合背包：外循环target,内循环nums,target正序且target>=nums[i];
4、分组背包：这个比较特殊，需要三重循环：外循环背包bags,内部两层循环根据题目的要求转化为1,2,3三种背包类型的模板

然后是问题分类的模板：
1、最值问题: dp[i] = max/min(dp[i], dp[i-nums]+1)或dp[i] = max/min(dp[i], dp[i-num]+nums);
2、存在问题(bool)：dp[i]=dp[i]||dp[i-num];
3、组合问题：dp[i]+=dp[i-num];

（1）如果是完全背包，即数组中的元素可重复使用并且不考虑元素之间顺序，arrs 放在外循环（保证 arrs 按顺序），target在内循环。且内循环正序。
（2）如果组合问题需考虑元素之间的顺序，需将 target 放在外循环，将 arrs 放在内循环，且内循环正序


```



子数组问题

子序列问题

公共子序列问题

### 贪心

# AI算法

### 常见算子的时间复杂度分析、参数分析、计算量分析、梯度计算分析

### Transformer完全解析

### 多目标检测与跟踪

#### 单阶段算法：YOLOv1-YOLOv8

#### 端到端：DETR,RT-DETR

#### 检测后跟踪：ByteTrack

### 面试常见问题汇总

# CUDA编程

### CUDA编程模型

### CUDA内存结构

### CUDA性能分析（Nsight systerm与Nsight compute的使用）

### CUDA算子编写与优化

#### reduce

#### layernorm

#### softmax

#### 激活函数类

#### gemv

#### flash attention

### CUDA的Stream

### CUDA编程总结

### CUDA面试常见问题汇总

```
1. ### CUDA的线程组织结构

2. ### CUDA的存储体系结构，每一种存储的优缺点，该如何合理使用。

   ```
   全局内存：
   这是GPU中最大的内存，即我们常说的HBM内存，可以被所有块上的所有线程访问，当我们在GPU中初始化一个值而不指定其存储位置时，它会自动存储在全局内存中。然而，访问全局内存通常比其他内存类型慢，因此需要进行优化以避免性能下降，可以通过合并内存访问和使用共享内存来优化性能。
   
   共享内存：
   同一个Block内的线程可以通过共享内存共享数据。相比访问全局内存至少快个10倍，但共享内存的容量有限（通常为几十KB），无法被其他线程块访问。由于共享内存和缓存内存提供快速的访问速度，因此我们经常在计算过程中使用它们来存储数据。典型的方法是首先将所有数据从 CPU 复制到 GPU 并将其存储在全局内存中。然后，我们将数据分解成更小的部分（块）并将它们推送到共享内存中进行计算。计算完成后，结果将被推回全局内存。
   
   本地内存（Local Memory）
   每个线程都可以使用自己的本地内存，可以在其中存储临时变量。它具有最小的范围并且专用于每个单独的线程。
   
   
   GPU由多个SM组成，每个SM内有多个warp调度器。
   
   全局内存
   L2 cache
   L1 cache
   
   共享内存->物理上和L1 cache是在一起的，可以配置大小。一个block里共享，使用时需要注意同步。需要注意bank conflict
   寄存器->线程私有，自动分配
   local内存->寄存器溢出的时候会使用
   
   ```

   

3. ### GPU每一代的新特性有了解过吗？应该从哪里去了解详细信息？

   ```
   nvida官网，有一些架构的白皮书。
   CUDA tooklits里有对应架构的调优指南，这里讲得具体一些。
   
   
   https://www.nvidia.cn/technologies/
   Pascal架构    1050ti
   Volta架构
   Turing架构
   Ampere架构   RTX3080TI
   
   
   举例，比如在Ampere架构架构上提供了原生的Reduce操作，支持FP64，BFloat16的tensorcore
   
   
   ```

   

4. ### CUDA stream的概念，为什么要使用多个stream？

   ```
   CUDA Stream是指一堆异步的CUDA操作，它们按照主机（Host）代码确定的顺序在设备（Device）上执行。这些操作可以包括主机和设备之间的数据传输、内核（Kernel）启动以及其他由主机发起但由设备处理的命令。Stream允许操作在其中排队，并确保它们在先前的所有操作之后执行，从而提供了一种管理和组织异步操作的方式。
   
   当GPU在执行一个内核（Kernel）时，主机（Host）可能需要将数据从内存传输到GPU或从GPU传输回内存。通过使用多个Stream，可以在一个Stream中执行内核操作，同时在另一个Stream中执行数据传输操作。这样，数据传输和内核执行可以重叠进行，从而提高GPU的利用率。
   ```

   

5. ### GPU和CPU分别适合执行哪些程序？结合它们的硬件架构解释一下为什么它们有各自的优势。

6. ### 说明一下神经网络加速器与CPU、GPU的区别，他们各自有何优势？

7. ### 半精度浮点数FP16各个部分的具体位数，为什么要有半精度浮点数？

8. ### TensorCore的加速原理

9. ### MPI，OpenMP以及CUDA各自适用的加速场景。

10. ### RDMA相关问题。

11. ### 平时如何进行kernel的优化，会用到哪些工具？

12. ### CPU上哪些并行优化方法？

13. ### ARM相关的库有了解过吗？

14. ### PTX有了解过吗？

15. ### roofline模型有什么用？如何确定最优的BLOCK_SIZE。

16. ### GPU资源调度有哪些方法？

17. ### 稀疏矩阵的存储格式有哪些？稀疏矩阵的应用场景？稀疏矩阵计算与稠密矩阵计算有何不同？

18. ### 如何计算CPU指令的吞吐量和时延?
```



# 推理框架

### 带显卡&&服务器端&&桌面设备：TensorRT

### 移动端&&嵌入式设备：ncnn

### 大模型推理：FastLLM、VLLM

### 推理框架总结&&常见问题汇总

# 模型量化

### 量化基本知识

### 量化加速原理

### 量化常见问题总结

# 大模型推理加速

### flash attention

### page attention

### kv cache

### 大模型量化&&前沿的量化论文

# 手撕代码

### leetcode

### c++的一些设计模式

#### 生产者消费者模型

```c++

#include<algorithm>
#include<thread>
#include<mutex>
#include<condition_variable>
#include<queue>
#include<iostream>
#include<chrono>

using namespace std;

static int index = 0;
class Prodeuce_consumer {
	
public:	
	Prodeuce_consumer() {
		max_size = 10;
	}

	Prodeuce_consumer(int size) {
		max_size = size;
	}

	Prodeuce_consumer(const Prodeuce_consumer& p1) {
		max_size = p1.max_size;
	}

	Prodeuce_consumer& operator =(const Prodeuce_consumer& p1) {
		if (&p1 == this) return *this;
		Prodeuce_consumer p = Prodeuce_consumer(p1.max_size);
		return p;
	}

	virtual ~Prodeuce_consumer() {

	}

	void run() {
		thread t1(&Prodeuce_consumer::procuder,this);
		thread t2(&Prodeuce_consumer::consumer, this);
		thread t3(&Prodeuce_consumer::consumer, this);
		thread t4(&Prodeuce_consumer::consumer, this);

		t1.join();
		t2.join();
		t3.join();
		t4.join();
	}


	void procuder() {
			
		while (1) {
			
			this_thread::sleep_for(chrono::milliseconds(100));
			{
				unique_lock<mutex> ul(mu);
				cond.wait(ul, [&]() {
					return que.size() < max_size;
					});
				que.push(index++);
				cout << "producer is " << index << "  ";
				cout << "que size is " << que.size() << endl;
			}
			


		}

	}


	void consumer() {

			
		while (1) {
 
			{
				lock_guard<mutex> l(mu);
				if (!que.empty()) {
					int cur = que.front();
					que.pop();
					cout <<"ID IS   "<<this_thread::get_id()<< "   consumer run " << cur << endl;
					cond.notify_all();
				}
			}
			this_thread::sleep_for(chrono::milliseconds(500));
			
		}


	}

private:
	int max_size;
	queue<int> que;
	mutex mu;
	condition_variable cond;

};




int main()
{
	Prodeuce_consumer p1;
	p1.run();
}

```

#### 线程安全的单例模式

```c++
class Test {

	Test& get_instance() {
		static Test t1;
		return t1;
	}

private:
	Test() {};
	Test(const Test& t) = delete;
	Test& operator=(const Test& t) = delete;
};


template <class T>
class Singleton
{
private:
    Singleton() = default;
    ~Singleton() = default;
    Singleton(const Singleton&)=delete;
    Singleton& operator=(const Singleton&)=delete;
 
public:
    static T* instance()
    {
        std::call_once(_flag, [&](){
            _instance = new T();
        });
        return _instance;
    }
 
private:
    static T* _instance;
    static std::once_flag _flag;
};
 

```



智能指针

```c++



//share_ptr
template<class T>
class SmartPtr{
public:
	SmartPtr(T* ptr = NULL): _ptr(ptr), _pcount(new int(1)) {} //构造函数
	SmartPtr(const SmartPtr& s): _ptr(s.ptr), _pcount(s._pcount){  //拷贝构造函数
		*(_pcount)++; //用指针进行count操作能够方便控制不同智能指针对象的计数值
	}
	SmartPtr<T>& operator=(const SmartPtr& s){  //重载 = ，赋值函数
		if(this != &s){ //检测自我赋值
			if(--(*(this->_pcount)) == 0){
				delete this->_ptr;
				delete this->_pcount;
			}
			_ptr = s._ptr;
			_pcount = s._pcount;
			*(_pcount)++;
		}
		return *this;
	}
	T& operator*(){
		return *(this->_ptr);
	}
	T* operator->(){
		return this->_ptr;
	}
	~SmartPtr(){ //析构函数要进行判定，count为0才会delete，delete之后避免野指针要赋值nullptr
		--(*(this->_pcount));
		if(this->_pcount == 0){
			delete _ptr;
			_ptr = nullptr;
			delete _pcount;
			_pcount = nullptr;
		}
	}
private:
	T* _ptr;
	int* _pcount;
};

template <typename T> 
class unique_ptr {
private:
  T *ptr_resource = nullptr;

public:
  // explicit构造函数是用来防止隐式转换, 即不允许写成unique_ptr<T> tempPtr = T;
  // std::move是将对象的状态或者所有权从一个对象转移到另一个对象，只是转移，没有内存的搬迁或者内存拷贝所以可以提高利用效率,改善性能.
  // move之后，raw_resource内部的资源将不能再被raw_resource使用
  explicit unique_ptr(T *raw_resource) noexcept
      : ptr_resource(std::move(raw_resource)) {}
  unique_ptr(std::nullptr_t) : ptr_resource(nullptr) {}

  unique_ptr() noexcept : ptr_resource(nullptr) {}

  // 析构时, 释放托管的对象资源
  ~unique_ptr() noexcept { delete ptr_resource; }

    
  unique_ptr(const unique_ptr<T> &) noexcept = delete;
  unique_ptr &operator=(const unique_ptr &) noexcept = delete;

public:
  //&& 是右值引用，见https://zhuanlan.zhihu.com/p/107445960
  // 允许移动语义。虽然无法复制unique_ptr，但可以安全地移动。
  // 例子：unique_ptr<Test> tPtr3(std::move(tPtr1));
  unique_ptr(unique_ptr &&move) noexcept {
    std::cout << "construct for unique_ptr&&" << std::endl;
    move.swap(*this);
  }
  // ptr = std::move(resource)
  unique_ptr &operator=(unique_ptr &&move) noexcept {
    std::cout << "operator= for unique_ptr&&" << std::endl;
    move.swap(*this);
    return *this;
  }


public:
  // overloaded operators
  T *operator->() const noexcept { return this->ptr_resource; }
  T &operator*() const noexcept { return *this->ptr_resource; }
  // 额外说明noexcept
  // noexcept C++11关键字,
  // 告诉编译器，函数中不会发生异常,有利于编译器对程序做更多的优化
  // C++中的异常处理是在运行时而不是编译时检测的。为了实现运行时检测，编译器创建额外的代码，然而这会妨碍程序优化
};

```





### cuda

#### reduce

```c++
//分配一个warp处理一个block里的数据
template<int WARPSIZE>
__device__ __forceinline__ float warp_reduce_add(float val)
{
    for(int mask=WARPSIZE>>1;mask>=1;mask>>=1){
        val+=__shfl_xor_sync(0xffffffff,val,mask);
    }
}


template<int warpsize>
__device__ warp_reduce_add(float val)
{
    for(int mask=warpsize>>1;mask>=1;mask>>=1){
        val+=__shfl_xor_sync(0xffffffff,val,mask);
    }
    return val;
}

template<int warpsize>
__device__ warp_reduce_max(float val)
{
    for(int mask=warpsize>>1;mask>=1;mask>>=1){
        val=fmax(__shfl_xor_sync(0xffffffff,val,mask),val);
    }
    return val;
}


template<int warpsize,int blocksize>
__device__ block_reduce_sum(float val)
{

    __shared__ float sdata[blocksize/warpsize];

    int tid=threadIdx.x;
    int warp_index=tid/warpsize;
    int warp_thread=tid&(warpsize-1);
    int warp_num=blocksize/warpsize;

    val=warp_reduce_add<warpsize>(val);

    if(warp_thread==0) sdata[warp_index]=val;
    __sync_threads();

    val = (warp_thread < warp_num)?sdata[warp_thread]:0;

    val=warp_reduce_add<warpsize>(val);

    return val;

}

template<int warpsize,int blocksize>
__device__ block_reduce_max(float val)
{

    __shared__ float sdata[blocksize/warpsize];

    int tid=threadIdx.x;
    int warp_index=tid/warpsize;
    int warp_thread=tid&(warpsize-1);
    int warp_num=blocksize/warpsize;

    val=warp_reduce_max<warpsize>(val);

    if(warp_thread==0) sdata[warp_index]=val;
    __sync_threads();

    val = (warp_thread < warp_num)?sdata[warp_thread]:-1000.0;

    val=warp_reduce_max<warpsize>(val);

    return val;

}
    return val;
}
```

softmax

```c++
template<int WARPSIZE,int BLCOKSIZE,int COLS>
__device__ void warp_softmax(float input,float output,int rows,int cols)
{

    constexpr int nums=COLS/WARPSIZE;
    __shared__ float sdata[nums];

    int tid=threadIdx.x;
    int row_index = blockIdx.x;

    float* row_ptr = input+row_index*cols;
    float* out_prt = output+row_index*cols;

    float val_max=-10000f;
    for(int i=0;i<num;i++){
        sdata[i]=input[tid+i*WARPSIZE];
        val_max=fmax(sdata[i],val_max);
    }

    val_max = warp_reduce_max<WARPSIZE>(val_max);

    float val_sum=0.0f;
    for(int i=0;i<num;i++){
        sdata[i]=exp(sdata[i]-val_max)
        val_sum=val_sum+sdata[i];
    }
    val_sum = warp_reduce_sum<WARPSIZE>(val_sum);


    for(int i=0;i<num;i++){
        out_prt[tid+i*WARPSIZE]]=data[i]/val_sum;
    }

}
```





### 手撕一些算子（用c++或者pytorch）

# 面试经验

