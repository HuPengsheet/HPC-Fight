# 高性能计算求职面试全攻略



# c/c++

### c++内存布局

![image-20240611122949435](/home/hp/code/HPC-Fight/HPC-Fight/image/image-20240611122949435.png)

```
常量区：虚函数表、const修饰的全局变量、字符串常量
程序代码：函数、类函数
全局数据区：全局变量、静态变量
.bss:.主要作用是存放程序中未初始化的全局变量和静态变量。这些变量在编译时没有明确赋初值，因此在程序加载到内存时，系统会自动将.bss段的内存空间清零，以保证变量在使用前具备确定的初值。

```



### 构造函数

```c++
#include <iostream>  
#include <cstring>  
  
class String {  
private:  
    char* data;  
    size_t length;  
  
public:  
    // 默认构造函数，创建一个空字符串  
    String() : data(nullptr), length(0) {  
    }  
  
    // 构造函数，接收一个C风格的字符串并复制其内容  
    String(const char* str) {  
        length = strlen(str);  
        data = (char*)malloc(length + 1); // 分配内存，+1用于字符串结束符'\0'  
        if (data != nullptr) {  
            strcpy(data, str); // 复制字符串  
        }  
    }  
  
    // 拷贝构造函数  
    String(const String& other) {  
        length = other.length;  
        data = (char*)malloc(length + 1); // 分配内存  
        if (data != nullptr) {  
            strcpy(data, other.data); // 复制字符串  
        }  
    }  
  
    // 析构函数，释放之前分配的内存  
    ~String() {  
        free(data); // 释放内存  
    }  
  
    // 拷贝赋值运算符  
    String& operator=(const String& other) {  
        if (this != &other) { // 避免自赋值  
            free(data); // 释放原有内存  
            length = other.length;  
            data = (char*)malloc(length + 1); // 分配新内存  
            if (data != nullptr) {  
                strcpy(data, other.data); // 复制字符串  
            }  
        }  
        return *this;  
    }  
  
    // 获取字符串长度  
    size_t getLength() const {  
        return length;  
    }  
  
    // 打印字符串  
    void print() const {  
        if (data != nullptr) {  
            std::cout << data << std::endl;  
        } else {  
            std::cout << "Empty string" << std::endl;  
        }  
    }  
  
    // 其他成员函数可以在这里添加  
};  
  

```

#### C++所有构造函数

类对象被创建时，编译器为对象分配内存空间，并自动调用构造函数，由构造函数完成成员的初始化工作。

因此构造函数的的作用是初始化对象的成员函数。

**默认构造函数：**如果没有人为构造函数，则编译器会自动默认生成一个无参构造函数。

**一般构造函数：**包含各种参数，一个类可以有多个一般构造函数，前提是参数的个数和类型和传入参数的顺序都不相同，根据传入参数调用对应的构造函数。

**拷贝构造函数：**拷⻉构造函数的函数参数为对象本身的引用，用于根据⼀个已存在的对象复制出⼀个新的该类的对象，⼀般在函数中会将已存在的对象的数据成员的值⼀⼀复制到新创建的对象中。如果没有显示的写拷⻉构造函数，则系统会默认创建⼀个拷⻉构造函数，但当类中有指针成员时，最好不要使⽤编译器提供的默认的拷⻉构造函 数，最好⾃⼰定义并且在函数中执⾏深拷⻉。

**移动构造函数：**有时候我们会遇到这样一种情况，我们用对象a初始化对象b后对象a我们就不在使用了，但是对象a的空间还在呀（在析构之前），既然拷贝构造函数，实际上就是把a对象的内容复制一份到b中，那么为什么我们不能直接使用a的空间呢？这样就避免了新的空间的分配，大大降低了构造的成本。这就是移动构造函数设计的初衷。拷贝构造函数中，对于指针，我们一定要采用深层复制，而移动构造函数中，对于指针，我们采用浅层复制。

> 但是指针的浅层复制是非常危险的。浅层复制之所以危险，是因为两个指针共同指向一片内存空间，若第一个指针将其释放，另一个指针的指向就不合法了（pointer dangling）。所以我们只要避免第一个指针释放空间就可以了。避免的方法就是将第一个指针（比如a->value）置为NULL，这样在调用析构函数的时候，由于有判断是否为NULL的语句，所以析构a的时候并不会回收a->value指向的空间（同时也是b->value指向的空间）

**赋值构造函数：**=运算符的重载，类似拷贝构造函数，将=右边的类对象赋值给类对象左边的对象，不属于构造函数，=两边的对象必须都要被创建。

**类型转换构造函数：**有时候不想要隐式转换，用explict关键字修饰。一般来说带一个参数的构造函数，或者其他参数是默认的构造函数      



#### 什么情况下会调用拷贝构造函数？

1. 对象以值传递的方式进入函数体
2. 对象以值传递的方式从函数返回
3. 一个对象需要另外一个对象初始化



#### 为什么拷贝构造函数必须是引用？

**为了防止递归调用。**

如果不用引用，就会是值传递的方式，但是值传递会调用拷贝构造函数生成临时对象，从而又调用一次拷贝构造函数。就这样无穷的递归下去。

**如果是指针类型**

就变成了一个带参数的构造函数了。。。

比如`A(A* test)`



#### 构造函数析构函数是否能抛出异常

**构造函数可以抛出异常**

对象只有在构造函数执行完成之后才算构造妥当，c++只会析构已经完成的对象。因此如果构造函数中发生异常，控制权就需要转移出构造函数，执行异常处理函数。在这个过程中系统会认为对象没有构造成功，导致不会调用析构函数。在构造函数中抛出异常会导致当前函数执行流程终止，在构造函数流程前构造的成员对象会被释放，但是如果在构造函数中申请了内存操作，则会造成内存泄漏。另外，如果有继承关系，派生类中的构造函数抛出异常，那么基类的构造函数和析构函数可以照常执行的。

解决办法：用智能指针来管理内存就可以

**C++标准指明析构函数不能、也不应该抛出异常**

C++异常处理模型最大的特点和优势就是对C++中的面向对象提供了最强大的无缝支持。那么如果对象在运行期间出现了异常，C++异常处理模型有责任清除那些由于出现异常所导致的已经失效了的对象(也即对象超出了它原来的作用域)，并释放对象原来所分配的资源， 这就是调用这些对象的析构函数来完成释放资源的任务，所以从这个意义上说，析构函数已经变成了异常处理的一部分。

析构函数不能抛出异常原因有两个：

1. 如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会执行，会造成诸如资源泄漏的问题。
2. 异常发生时，c++的异常处理机制在异常的传播过程中会进行栈展开（stack-unwinding）。在栈展开的过程中就会调用已经在栈构造好的对象的析构函数来释放资源，此时若其他析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃。

解决办法：把异常完全封装在析构函数内部，决不让异常抛出函数之外，代码如下：

```c++
DBConn::~DBconn()
{
    try
    {
	    db.close(); 
    }
    catch(...)
    {
        abort();
    }
}
//如果close抛出异常就结束程序，通常调用abort完成：
```



#### 创建派生类对象，构造函数的执行顺序是什么？析构函数的执行顺序？

首先要知道类的构造函数不能被继承，构造函数不能被继承是有道理的，因为即使继承了，它的名字和派生类的名字也不一样（构造函数名字和类名一样），不能成为派生类的构造函数，当然更不能成为普通的成员函数。在设计派生类时，对继承过来的成员变量的初始化工作也要由派生类的构造函数完成，但是大部分基类都有private属性的成员变量，它们在派生类中无法访问，更不能使用派生类的构造函数来初始化。这种矛盾在C++继承中是普遍存在的，解决这个问题的思路是：**在派生类的构造函数中调用基类的构造函数**。

对象创建时候执行顺序是：**静态代码 --> 非静态代码 --> 构造函数。**静态代码包括（静态方法，静态变量，静态代码块等），非静态代码即（成员方法，成员变量，成员代码块等）。代码块中或者成员变量中如果有类对象的话，肯定要先将类对象创建出来。所以说先执行代码块再执行构造函数，而且如果代码块中有多个成员变量，则按照成员变量的声明顺序进行构造。初始化列表的顺序, 不影响成员变量构造顺序

因为静态变量等这些在内存中属于全局变量，所以要先创建。然后类会查看成员函数的相关信息，为该类的对象中的每个成员变量分配相应的存储空间，然后再执行构造函数创建对象，如果构造函数有初始化，则将值放到准备好的内存空间中。

**构造函数执行顺序**

1. 基类构造函数。如果有多个基类，则构造函数的调用顺序是该基类在派生类中出现的顺序，而不是他们在成员初始化列表中的顺序。
2. 成员类对象构造函数。如果有多个成员类构造函数调用顺序是对象在类中被声明的顺序，而不是他们在成员初始化列表中的顺序
3. 派生类构造函数

**析构函数顺序**

1. 派生类析构函数
2. 成员类对象的析构函数
3. 调用基类的析构函数



#### C++成员变量的初始化顺序问题

```c++
class A
{
private:
    int n1;
    int n2;
public:
    A():n2(0),n1(n2+2){}
    void Print(){
        cout << "n1:" << n1 << ", n2: " << n2 <<endl;
    }
};

int main()
{
    A a;
    a.Print();
    return 1;
}

//输出：n1: 是一个随机数；n2: 0
//有的编译器是n1:2, n2=0
```

1. 成员变量在使用初始化列表初始化时，只与定义成员变量的顺序有关，与构造函数中初始化成员列表的顺序无关。因为成员变量的初始化次序是根据变量在内存中次序有关，而内存中的排列顺序早在编译期就根据变量的定义次序决定了。
2. 如果不使用初始化列表初始化，在构造函数内初始化时，此时与成员变量在构造函数中的位置有关。
3. 类成员在定义时，是不能初始化的
4. 类中const成员常量必须在构造函数初始化列表中初始化。
5. 类中static成员变量，必须在类外初始化。

**变量的初始化顺序：**

1. 初始化基类中的静态成员变量和静态代码块，按照在程序中出现的顺序初始化；
2. 初始化派生类中的静态成员变量和静态代码块，按照在程序中出现的顺序初始化；
3. 初始化基类的普通成员变量和代码块，再执行父类的构造方法；
4. 初始化派生的普通成员变量和代码块，在执行子类的构造方法；

### c++新特性

#### const与constexpr

```
c++98：const有两个语义，分别是 常量和只读
c++11之后： 
	const:表示只读
	constexpr:表示常量，在编译期会被计算出来
```

#### c++11多线程

```
创建线程：
	thread t1();

管理线程：
	void join()	等待线程结束并清理资源（会阻塞）
	bool joinable()	返回线程是否可以执行join函数
	void detach()	将线程与调用其的线程分离，彼此独立执行（此函数必须在线程创建时立即调用，且调用此函数会使其不能被join）

线程传参：
    值引用必须用std::ref(),包装
void func(int& a)
{   
    cout<<"func &"<<endl;
    a+=10;
}
int a=10;
thread t1(func,std::ref(a);
          

原子操作与锁：
    atomic_int n = 0; 对n的操作都是线程安全的

互斥锁：std::mutex
void lock():
	将mutex上锁。如果mutex已经被其它线程上锁，那么会阻塞，直到解锁；如果mutex已经被同一个线程锁住，那么会产生死锁。
void unlock():
	解锁mutex，释放其所有权。如果有线程因为调用lock()不能上锁而被阻塞，则调用此函数会将mutex的主动权随机交给其中一个线程；如果mutex不是被此线程上锁，那么会引发未定义的异常。
bool try_lock():
	尝试将mutex上锁。如果mutex未被上锁，则将其上锁并返回true；如果mutex已被锁则返回false。
	
递归锁：std::recursive_mutex，可以支持多次上锁，不会发生死锁现象


```



lock_guard与unique_lock的区别

```c++
template<typename _Mutex>
class lock_guard
{
public:
  typedef _Mutex mutex_type;

  explicit lock_guard(mutex_type& __m) : _M_device(__m)
  { _M_device.lock(); }

  lock_guard(mutex_type& __m, adopt_lock_t) noexcept : _M_device(__m)
  { } // calling thread owns mutex

  ~lock_guard()
  { _M_device.unlock(); }

  lock_guard(const lock_guard&) = delete;
  lock_guard& operator=(const lock_guard&) = delete;

private:
  mutex_type&  _M_device;
};


mutex lock_;
lock_guard<mutex> l1(lock_);
本质上就是初始化的时候上锁，lock_guard对象销毁的时候解锁
lock_guard的拷贝和复制构造函数都delete了
    
 
    
 unique_lock的使用更为灵活
 比如 unique_lock<mutex> lockguard(m1, try_to_lock_t());	//正常,对已经加锁的 mutex 尝试加锁不会导致崩溃

也可以提前解锁
void CriticalSection_1()
{
	unique_lock<mutex> lockguard(m1);
	lockguard.unlock();
	CriticalSection_2();
}
```



#### 左值与右值、左值引用与右值引用、万能引用与完美转发

左值：能够用&取地址的表达式是左值表达式。

- ​    函数名和变量名（实际上是函数指针和具名变量，具名变量等）
- ​    返回左值引用的函数调用
- ​    前置自增/自减运算符连接的表达式++i/--i
- ​    由赋值运算符或复合赋值运算符连接的表达式(a=b、a+=b、a%=b）
- ​    解引用表达式*p
- ​    字符串字面值"abc"等。

纯右值：满足下列条件之一：本身就是赤裸裸的、纯粹的字面值。或求值结果相当于字面值或是一个不具名的临时对象。

- ​    除字符串字面值以外的字面值
- ​    返回非引用类型的函数调用
- ​    后置自增/自减运算符连接的表达式i++/i--
- ​    算术表达式（a+b、a&b、a<<b）
- ​    逻辑表达式（a&&b、a||b、~a）
- ​    比较表达式（a==b、a>=b、a<b）
- ​    取地址表达式（&a）等。

将亡值：在C++11之前的右值和C++11中的纯右值是等价的。C++11中的将亡值是随着右值引用的引入而新引入的。换言之“将亡值”概念的产生，是由右值引用的产生而引起的，将亡值与右值引用息息相关。所谓的将亡值表达式，就是下列表达式：

- ​    返回右值引用的函数的调用表达式
- ​    转换为右值引用的转换函数的调用表达式（std::move）



左值引用与右值引用

```c++
int a=10;
int& b=a;

/*
  a是左值
  b是左值引用，引用的是a
  本质上是一个常量指针，这个指针值指向的地址就是，引用对象的地址，是一个常量不可更改
  
*/



int getval()
{	
   int a=10;
	return a;
}

int&& c=getval();

/*
  getval()的返回值是一个右值，且是一个将亡值
  c是右值引用，延长了其生命周期
*/
```



为什么要有右值与右值引用？为了移动语义：std::move()

```c++
/*
考虑这么一个场景，有一个表单
string 是这个表的名字，std::vector<int>储存的是表的数据
*/

std::map<string, std::vector<int>> mapTable;


void fun()
{
    std::vector<int> vecRow;
    for(){
    vecRow.push_back(...);
    }
    mapTable["列名1"] = vecRow;
}

```

​	先新建了一个表项，然后给这个循环添加元素，最后在总表单中添加刚刚写好的一个表项。

```c++
mapTable["列名1"] = vecRow;
```

​	首先执行这行代码的时候，会调用vector的拷贝构造（如果是其他自定义的类，对应调用其拷贝构造）完成在总表单的初始化，函数调用后vecRow被销毁，又会调用其析构造函数。

​	但实际上我们要在总表单上添加的数据项和这个临时变量的值都是一样的，只是因为这个临时变量在出func这个作用域后，会被销毁，所以不能直接引用。这个时候就有了移动语义了

```c++
std::vector<int> vecRow;
for(){
vecRow.push_back(...);
}
mapTable["列名1"] = std::move(vecRow);
```

std::move(vecRow);把vecRow变成一个右值，此时就会调用移动构造，移动构造只是把控制权交给别人，没有发生数据复制。可以提高效率。



为什么会有万能引用？减少函数重载的代码量



先看一个示例代码

```c++
void func(int&& a)
{
    cout<<"int&&"<<endl;
}

void func(int& a)
{
    cout<<"int&"<<endl;
}

int get_val(){
    return 10;
}

int main(){
    int a=10;
    func(a);
    func(get_val());
}

/*
输出结果
int&
int&&  
*/
```



按上面的结果，如果&与&&是有函数重载的

```c++
template<class T>
void func(T& a)
{
    
}
```







# 操作系统&&计算机体系结构

CPU的基本结构

# 数据结构与算法

```
和为 K 的子数组
最小覆盖子串
区间合并(不是特别熟练)
除自身以外数组的乘积
缺失的第一个正数
螺旋矩阵

两数相加
对称二叉树
二叉树的直径
二叉树展开为链表
二叉树的最近公共祖先
二叉树中的最大路径和


```



```c++
int n = 1005; // n根据题目中节点数量而定，一般比节点数量大一点就好
vector<int> father = vector<int> (n, 0); // C++里的一种数组结构

// 并查集初始化
void init() {
    for (int i = 0; i < n; ++i) {
        father[i] = i;
    }
}
// 并查集里寻根的过程
int find(int u) {
    return u == father[u] ? u : father[u] = find(father[u]); // 路径压缩
}

// 判断 u 和 v是否找到同一个根
bool isSame(int u, int v) {
    u = find(u);
    v = find(v);
    return u == v;
}

// 将v->u 这条边加入并查集
void join(int u, int v) {
    u = find(u); // 寻找u的根
    v = find(v); // 寻找v的根
    if (u == v) return ; // 如果发现根相同，则说明在一个集合，不用两个节点相连直接返回
    father[v] = u;
}


```

```c++


class Trie {
private:
    bool isEnd;
    Trie* next[26];
public:
    Trie() {
        isEnd = false;
        memset(next, 0, sizeof(next));
    }
    void insert(string word) {
        Trie* node = this;
        for (char c : word) {
            if (node->next[c-'a'] == NULL) {
                node->next[c-'a'] = new Trie();
            }
            node = node->next[c-'a'];
        }
        node->isEnd = true;
    }

      bool search(string word) {
        Trie* node = this;
        for (char c : word) {
            node = node->next[c - 'a'];
            if (node == NULL) {
                return false;
            }
        }
        return node->isEnd;                                                                    bvv
            
    }

    
    bool startsWith(string prefix) {
        Trie* node = this;
        for (char c : prefix) {
            node = node->next[c-'a'];
            if (node == NULL) {
                return false;
            }
        }
        return true;
    }
};

```



### 排序

```c++
void quick_sort(int q[], int l, int r)
{
    if (l >= r) return;

    int i = l - 1, j = r + 1, x = q[l + r >> 1];
    while (i < j)
    {
        do i ++ ; while (q[i] < x);
        do j -- ; while (q[j] > x);
        if (i < j) swap(q[i], q[j]);
    }
    quick_sort(q, l, j), quick_sort(q, j + 1, r);
}

void merge_sort(int q[], int l, int r)
{
    if (l >= r) return;

    int mid = l + r >> 1;
    merge_sort(q, l, mid);
    merge_sort(q, mid + 1, r);

    int k = 0, i = l, j = mid + 1;
    while (i <= mid && j <= r)
        if (q[i] <= q[j]) tmp[k ++ ] = q[i ++ ];
        else tmp[k ++ ] = q[j ++ ];

    while (i <= mid) tmp[k ++ ] = q[i ++ ];
    while (j <= r) tmp[k ++ ] = q[j ++ ];

    for (i = l, j = 0; i <= r; i ++, j ++ ) q[i] = tmp[j];
}

long long qmi(long long a,int b,int p)
{
    long long res=1;
    while(b)//对b进行二进制化,从低位到高位
    {
        //如果b的二进制表示的第0位为1,则乘上当前的a
        if(b&1) res = res *a %p;
        //b右移一位
        b>>=1;
        //更新a,a依次为a^{2^0},a^{2^1},a^{2^2},....,a^{2^logb}
        a=a*a%p;
    }
    return res;
}
```



### 链表

```
auto low=head;
auto fast=head;

while(fast!=tail&&fast->next!=tail){
    low=low->next;
    fast=fast->next->next;
}
auto mid=low;



right
auto low=head;
auto fast=head;

while(fast!=tail&&fast->next->next!=tail){
    low=low->next;
    fast=fast->next->next;
}
auto mid=low;

```



### 二叉树

### 双指针

### 堆&&栈&&队列

### 回溯

### 动态规划

一般的动态规划问题

背包类问题

```
分类解题模板

背包问题大体的解题模板是两层循环，分别遍历物品nums和背包容量target，然后写转移方程，
根据背包的分类我们确定物品和容量遍历的先后顺序，根据问题的分类我们确定状态转移方程的写法

首先是背包分类的模板：
1、0/1背包：外循环nums,内循环target,target倒序且target>=nums[i];
2、完全背包：外循环nums,内循环target,target正序且target>=nums[i];
3、组合背包：外循环target,内循环nums,target正序且target>=nums[i];
4、分组背包：这个比较特殊，需要三重循环：外循环背包bags,内部两层循环根据题目的要求转化为1,2,3三种背包类型的模板

然后是问题分类的模板：
1、最值问题: dp[i] = max/min(dp[i], dp[i-nums]+1)或dp[i] = max/min(dp[i], dp[i-num]+nums);
2、存在问题(bool)：dp[i]=dp[i]||dp[i-num];
3、组合问题：dp[i]+=dp[i-num];

（1）如果是完全背包，即数组中的元素可重复使用并且不考虑元素之间顺序，arrs 放在外循环（保证 arrs 按顺序），target在内循环。且内循环正序。
（2）如果组合问题需考虑元素之间的顺序，需将 target 放在外循环，将 arrs 放在内循环，且内循环正序


```



子数组问题

子序列问题

公共子序列问题

### 贪心

# AI算法

### 常见算子的时间复杂度分析、参数分析、计算量分析、梯度计算分析



#### 卷积

```
class torch.nn.Conv2d
(in_channels, out_channels, kernel_size, 
stride=1, padding=0, dilation=1, groups=1, bias=True, 
padding_mode='zeros', device=None, dtype=None
)
```

##### 卷积的参数量

out_channels✖in_channels✖kernel_w✖kernel_h+out_channels

##### 卷积的FLOPs（不考虑strinde的话）

out_channels✖in_channels✖kernel_w✖kernel_h✖2✖w✖h

##### 卷积的时间复杂度

out_c✖in_c✖w✖h✖kernel_size

```c++
for(int x=0;x<out_c;x++){
    for(int y=0;y<h;y++){
        for(int z=0;z<w;z++)
            
            for(int c=0;c<in_c;c++){

              for(int num=0;num<kernel_size();num++){

              }
                    
                
 
            }
            
    }
}
```



#### 激活函数

```
Relu
Silu
Gelu
sigmod

```



#### POOL

```
最大池化
平均池化
自适应池化

池化的作用：下采样，降低计算量
梯度传播是怎么传播的
```



#### DropOut

```
def dropout(x, level):
    if level < 0. or level >= 1: #level是概率值，必须在0~1之间
        raise ValueError('Dropout level must be in interval [0, 1[.')
    retain_prob = 1. - level

    # 我们通过binomial函数，生成与x一样的维数向量。binomial函数就像抛硬币一样，我们可以把每个神经元当做抛硬币一样
    # 硬币 正面的概率为p，n表示每个神经元试验的次数
    # 因为我们每个神经元只需要抛一次就可以了所以n=1，size参数是我们有多少个硬币。
    random_tensor = np.random.binomial(n=1, p=retain_prob, size=x.shape) #即将生成一个0、1分布的向量，0表示这个神经元被屏蔽，不工作了，也就是dropout了
    print(random_tensor)

    x *= random_tensor
    print(x)
    x /= retain_prob

    return x

#对dropout的测试，大家可以跑一下上面的函数，了解一个输入x向量，经过dropout的结果  
x=np.asarray([1,2,3,4,5,6,7,8,9,10],dtype=np.float32)
dropout(x,0.4)



比如 输入的是【1，2，3，4，5，6】，然后丢弃的概率是0.5
则丢弃后，结果是 【0，2，0，0，5，6】
然后为为了保持数据的强度（或者说为了让数据的期望保持一致），或除以（1-0.5），也就是乘2，得到
0，4，0，0，10，12


梯度传播，0的梯度就是变为0，其他的梯度对应的除以/（1-0.5）

```





#### Batch Normalization

```
classtorch.nn.BatchNorm2d
(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)


对每个通道的特征做归一化
(B,N,H,W)
 
batch 1  (N,H,W)   b1_channel1(H,W)  b1_channel2(H,W)
batch 2  (N,H,W)   b2_channel1(H,W)  b2_channel2(H,W)
batch 3  (N,H,W)   b3_channel1(H,W)  b3_channel2(H,W)

把b1_channel1+b2_channel1+b3_channel1 加起来一共3HW个元素，做归一化


计算公式
(x-E(x))/(标准差)*r+b

对于训练的时候，均值和方差时通过计算出来的，并使用滑动平均的方法更新均值和方差
Et(x)=Et-1(x)*0.9+Et(x)*0.1

伽马和贝塔就是通过梯度下降学习得来

可学习参数一共num_features*2
总共的参数一共num_features*4


推理的时候 均值、标准差、伽马和贝塔，一共四个参数，均值和标准差是全局的均值和方差


(x-e)/a

```

![image-20240521183956226](/home/hp/.config/Typora/typora-user-images/image-20240521183956226.png)

进一步简化，可以把四个参数化简为两个



#### layernorm

```
对每个序列所有的特征做归一化

输入数据
class
torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True, bias=True, device=None, dtype=None)

batch_size,seq_len,dims

LayerNorm((seq_len,dims))

也就是：
batch_size1 seq_len，dims  在batch_size1内的seq_len✖dims个元素里做归一化，在对seq_len✖dims个元素做伽马和贝塔的放缩
batch_size2 seq_len, dims

```



#### RMSnrom

```
和layernorm一样，对每个序列所有的特征做归一化
只是计算方式不一样，计算速度会变快


class RMSNorm(torch.nn.Module):
    def __init__(self, dim: int, eps: float):
        super().__init__()
        self.eps = eps
        self.weight = nn.Parameter(torch.ones(dim))

    def _norm(self, x):
        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)

    def forward(self, x):
        output = self._norm(x.float()).type_as(x)
        return output * self.weight

```







#### Transformer

##### 模型总体结构

![image-20240520125329189](/home/hp/.config/Typora/typora-user-images/image-20240520125329189.png)

##### 多头注意力

1. qkv通过三个线性变换成QKV
2. dropout
3. 自注意力
4. S=（Q@K）*scale
5. softmax
6. O=S@V
7. o经过线性变换输出



##### 线性变换

```python
#@save
class MultiHeadAttention(nn.Module):
    """多头注意力"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 num_heads, dropout, bias=False, **kwargs):
        super(MultiHeadAttention, self).__init__(**kwargs)
        self.num_heads = num_heads
        self.attention = d2l.DotProductAttention(dropout)
        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)
        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)
        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)
        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)

    def forward(self, queries, keys, values, valid_lens):
        # queries，keys，values的形状:
        # (batch_size，查询或者“键－值”对的个数，num_hiddens)
        # valid_lens　的形状:
        # (batch_size，)或(batch_size，查询的个数)
        # 经过变换后，输出的queries，keys，values　的形状:
        # (batch_size*num_heads，查询或者“键－值”对的个数，
        # num_hiddens/num_heads)
        queries = transpose_qkv(self.W_q(queries), self.num_heads)
        keys = transpose_qkv(self.W_k(keys), self.num_heads)
        values = transpose_qkv(self.W_v(values), self.num_heads)

        if valid_lens is not None:
            # 在轴0，将第一项（标量或者矢量）复制num_heads次，
            # 然后如此复制第二项，然后诸如此类。
            valid_lens = torch.repeat_interleave(
                valid_lens, repeats=self.num_heads, dim=0)

        # output的形状:(batch_size*num_heads，查询的个数，
        # num_hiddens/num_heads)
        output = self.attention(queries, keys, values, valid_lens)

        # output_concat的形状:(batch_size，查询的个数，num_hiddens)
        output_concat = transpose_output(output, self.num_heads)
        return self.W_o(output_concat)

#@save
def transpose_qkv(X, num_heads):
    """为了多注意力头的并行计算而变换形状"""
    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)
    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，
    # num_hiddens/num_heads)
    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)

    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,
    # num_hiddens/num_heads)
    X = X.permute(0, 2, 1, 3)

    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,
    # num_hiddens/num_heads)
    return X.reshape(-1, X.shape[2], X.shape[3])


#@save
def transpose_output(X, num_heads):
    """逆转transpose_qkv函数的操作"""
    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])
    X = X.permute(0, 2, 1, 3)
    return X.reshape(X.shape[0], X.shape[1], -1)

```

​	对于输入q=k=v,它们的维度（batch_size,seq_len,dims）,经过三个线性层做线性变换，需要注意的是query_size==num_hiddens==dims，即经过线性层变换后，输出张量的维度不变

```
self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)
self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)
self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)
```

​	通过reshape来等价的实现多头注意力,把最后一个维度seq_len，分成（num_heads, -1），再把num_heads往前移动一个维度，

即（batch_size,num_heads,查询或者“键－值”对的个数,num_hiddens/num_heads),再把batch_size,num_heads,合并

```python
X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)

# 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,
# num_hiddens/num_heads)
X = X.permute(0, 2, 1, 3)

# 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,
# num_hiddens/num_heads)
return X.reshape(-1, X.shape[2], X.shape[3])
```



##### 自注意力

输入QKV,其维度为（m,seq_len,dims），分别是每个（seq_len,dims）做attention，也就是独立的做m个attention,每一个attention按如下方式计算

```python
attn_weight = query @ key.transpose(-2, -1) * scale_factor
attn_weight = torch.softmax(attn_weight, dim=-1)
result = attn_weight @ value
```



##### 带MASK自注意力

因为在大模型里的里，模型的输出是自回归的，也就是V的维度会越变越大，从（seq_len,dims）到（seq_len+1,dims），对于V中的每一行数据，也就是一个token，只能与前面的token做自注意力，通过MASK可以把Q@K里面的注意力分数设置为0

```
MASK=[
0,-INF,-INF,----,-INF
0,0,-INF,-INF,---,-INF
----------------------
0,0,0,----------,0,-INF
0,0,0,----------,0,0,0,
]


attn_weight = query @ key.transpose(-2, -1) * scale_factor
attn_weight += MASK
attn_weight = torch.softmax(attn_weight, dim=-1)
result = attn_weight @ value
```

##### MLP

其实就是两个线性层，中间加一个激活函数

```python
#@save
class PositionWiseFFN(nn.Module):
    """基于位置的前馈网络"""
    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,
                 **kwargs):
        super(PositionWiseFFN, self).__init__(**kwargs)
        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)
        self.relu = nn.ReLU()
        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)

    def forward(self, X):
        return self.dense2(self.relu(self.dense1(X)))

```

##### 参数和计算量分析

记transformer模型的层数为  l，隐藏层维度为 h ，注意力头数为  a,词表大小为  V，训练数据的批次大小为 b，序列长度为  s



权重的参数分析

```
对于一个transformer block，含有一个multi-head-attention和MLP

multi-head-attention，有4个线性变换矩阵(不带bias)，QKV的维度为（h*h）,O的维度为（h*h），参数量为4h*h
MLP,有两个线性变换矩阵（不带bias），分别是(h,4h),(4h,h),参数量为8h*h

总的参数量为12lh*h
```

### Transformer完全解析

### 多目标检测与跟踪

#### 单阶段算法：YOLOv1-YOLOv8

#### 端到端：DETR,RT-DETR

#### 检测后跟踪：ByteTrack

### 面试常见问题汇总

# CUDA编程

### CUDA编程模型

### CUDA内存结构

### CUDA性能分析（Nsight systerm与Nsight compute的使用）

### CUDA算子编写与优化

#### reduce

​	基于warp原语实现warp reduce和block reduce，并通过原子操作实现多个block之间的reduce。当输入数据量较大，优化单个线程处理的数据量，算子速度提高50%。

​	事实上block reduce更适合作为一个函数去给别的算子调用。

​	但如果单论求一行的reduce操作的话实际上的话，使用一个warp取处理一行数据就时最快的，最后调用一个warp reduce就可以了，因为这样的显存带宽利用率时最高的。

基础版本

```c++
//基于warp原语，实现warp_reduce
//val 是每个线程寄存器里的值
//返回后，每个线程寄存器的值，都是32个线程val值的和
template<int WARPSIZE>
__device__ __forceinline__ float warp_reduce_add(float val)
{
    for(int mask=WARPSIZE>>1;mask>=1;mask>>=1){
        val+=__shfl_xor_sync(0xffffffff,val,mask);
    }

    return val;
}


//对block里的所有线程取和
//调用两次 warp_reduce即可
template<int WARPSIZE,int BLOCKSIZE>
__device__ float block_reduce_add(float val)
{
    int tid=threadIdx.x;
    int warp_num = (BLOCKSIZE+WARPSIZE-1)/WARPSIZE;
    int warp_index=tid/WARPSIZE;
    int warp_thread=tid&(WARPSIZE-1); //取余，把 % 变成位运算可以提高计算速度

    __shared__ float data[WARPSIZE];

    val=warp_reduce_add<WARPSIZE>(val);

    if(warp_thread==0) data[warp_index]=val;
    __syncthreads();

    val = (warp_thread<warp_num)?data[warp_thread]:0;
    __syncthreads();

    val=warp_reduce_add<WARPSIZE>(val);

    return val;
}


//
template<int WARPSIZE,int BLOCKSIZE>
__global__ void multi_block_reduce_add(float *d_in, float *d_out)
{
    int tid=threadIdx.x;
    int block_index = blockIdx.x;

    const float* data_ptr = d_in+block_index*BLOCKSIZE;
    float val = data_ptr[tid];

    val = block_reduce_add<WARPSIZE,BLOCKSIZE>(val);
    if (tid == 0) atomicAdd(d_out, val);
}
```

使用warp处理一行数据，并增大warp处理的数据里量，减少atomicAdd的数量，速度可以提高50%～到100%

```c++
template<int WARPSIZE>
__device__ __forceinline__ float warp_reduce_add(float val)
{
    for(int mask=WARPSIZE>>1;mask>=1;mask>>=1){
        val+=__shfl_xor_sync(0xffffffff,val,mask);
    }

    return val;
}


//这里的BLOCKSIZE 实际上不是一个block里面的线程数，而是一个warp要处理的数据
//比如一共有N和数，512一组，一共有M=N/512组
//则kernel启动的时候，对应分配 <<<m,32>>>
//一个warp，32个线程通过循环去处理求和，在warp_reduce,求warp内的和
//需要进行的atomicAdd操作是，M次，所以增加一个warp要处理的数据量，可以减少atomicAdd操作
//但增加到一定量后，提速基本就停了，因为此时一个warp要处理的数据量大，对应的block数量少，atomicAdd相互竞争的情况也就少了，达到一个平衡
//我自己的机器3080ti 大概在一个warp处理1024个数据的时候，差不多就停止提速了
template<int WARPSIZE,int BLOCKSIZE>
__global__ void warp_level_reduce(float *d_in, float *d_out){

    int tid=threadIdx.x;
    int nums=(BLOCKSIZE+WARPSIZE-1)/WARPSIZE;
    int gtid=blockIdx.x*BLOCKSIZE+tid;    //每个block前32个线程

    float val=0;
    for(int index=0;index<nums;index++){
        val+=d_in[gtid+WARPSIZE*index];
    }
    val=warp_reduce_add<WARPSIZE>(val);
    if (tid == 0) atomicAdd(d_out, val);
}

```





#### layernorm

#### softmax

总体思路，根据数据量的大小采取不同的优化策略。

- 当数据量比较小时（PS：这里的数据量指的是，一行的数据量，比如输入数据维度是[ROWS，COLS]，数据量大指的是COLS过大）。此时采用一个warp处理一行数据，然后声明了一个寄存器数组去缓存每一行的数据，这样可以避免反复从global memory中读取。
- 当数据量比较大时（我自己的电脑的话，COLS>2048差不多就溢出了，一溢出的话速度直线下降，电脑直接卡死）。此时采用一个block处理一行数据，然后用shared来缓存每一行的数据。

```c++
template<int WARPSIZE>
__device__ __forceinline__ float warp_reduce_sum(float val)
{
    for(int mask=WARPSIZE>>1;mask>=1;mask>>=1){
        val += __shfl_xor_sync(0xffffffff,val,mask);
    }

    return val;

}

template<int WARPSIZE>
__device__ __forceinline__ float warp_reduce_max(float val)
{
    for(int mask=WARPSIZE>>1;mask>=1;mask>>=1){
        val =fmax(val,__shfl_xor_sync(0xffffffff,val,mask));
    }

    return val;
}

template<int WARPSIZE,int BLOCKSIZE>
__device__ float block_reduce_sum(float val)
{
    int tid=threadIdx.x;
    int warp_num = (BLOCKSIZE+WARPSIZE-1)/WARPSIZE;
    int warp_index=tid/WARPSIZE;
    int warp_thread=tid&(WARPSIZE-1); //取余

    __shared__ float data[WARPSIZE];

    val=warp_reduce_sum<WARPSIZE>(val);

    if(warp_thread==0) data[warp_index]=val;
    __syncthreads();

    val = (warp_thread<warp_num)?data[warp_thread]:0.0f;
    __syncthreads();

    val=warp_reduce_sum<WARPSIZE>(val);

    return val;
}

template<int WARPSIZE,int BLOCKSIZE>
__device__ float block_reduce_max(float val)
{
    int tid=threadIdx.x;
    int warp_num = (BLOCKSIZE+WARPSIZE-1)/WARPSIZE;
    int warp_index=tid/WARPSIZE;
    int warp_thread=tid&(WARPSIZE-1); //取余

    __shared__ float data[WARPSIZE];

    val=warp_reduce_max<WARPSIZE>(val);

    if(warp_thread==0) data[warp_index]=val;
    __syncthreads();

    val = (warp_thread<warp_num)?data[warp_thread]:-1000.0f;
    __syncthreads();

    val=warp_reduce_max<WARPSIZE>(val);

    return val;
}


//<<<rows,32>>>
template<int WARPSIZE,int BLOCKSIZE,int COLS_>
__global__ void warp_softmax(float* in_data,float* out_data,int rows,int cols)
{
    float rdata[COLS_/WARPSIZE];
    int thread_per_nums=COLS_/WARPSIZE;

    int tid=threadIdx.x;
    int block_index = blockIdx.x;

    const float* data_ptr=in_data+block_index*cols;
    float* save_ptr=out_data+block_index*cols;

    float max_val=-1000.0f;
    
    for(int i=0;i<thread_per_nums;i++){
        rdata[i]=data_ptr[tid+i*WARPSIZE];
        max_val=fmax(max_val,rdata[i]);
    }

    max_val=warp_reduce_max<WARPSIZE>(max_val);

    float sum_val=0.0f;
    for(int i=0;i<thread_per_nums;i++){
        rdata[i]=exp(rdata[i]-max_val);
        sum_val+=rdata[i];
    }

    sum_val=warp_reduce_sum<WARPSIZE>(sum_val);

    for(int i=0;i<thread_per_nums;i++){
        save_ptr[tid+i*WARPSIZE]=rdata[i]/sum_val;
    }

}


//256/32 8
//<<<rows/8,256>>>
template<int WARPSIZE,int BLOCKSIZE,int COLS_>
__global__ void block_warp_softmax(float* in_data,float* out_data,int rows,int cols)
{
    float rdata[COLS_/WARPSIZE];
    int thread_per_nums=COLS_/WARPSIZE;

    int tid=threadIdx.x;
    int warp_num=BLOCKSIZE/WARPSIZE;
    int warp_index=tid/WARPSIZE;
    int warp_thread=tid&(WARPSIZE-1);

    int block_index = blockIdx.x;

    const float* data_ptr=in_data+block_index*cols*warp_num+warp_index*cols;
    float* save_ptr=out_data+block_index*cols*warp_num+warp_index*cols;

    float max_val=-1000.0f;
    
    for(int i=0;i<thread_per_nums;i++){
        rdata[i]=data_ptr[warp_thread+i*WARPSIZE];
        max_val=fmax(max_val,rdata[i]);
    }

    max_val=warp_reduce_max<WARPSIZE>(max_val);

    float sum_val=0.0f;
    for(int i=0;i<thread_per_nums;i++){
        rdata[i]=exp(rdata[i]-max_val);
        sum_val+=rdata[i];
    }

    sum_val=warp_reduce_sum<WARPSIZE>(sum_val);

    for(int i=0;i<thread_per_nums;i++){
        save_ptr[warp_thread+i*WARPSIZE]=rdata[i]/sum_val;
    }

}


//<<<rows,256>>>
template<int WARPSIZE,int BLOCKSIZE,int COLS_>
__global__ void block_warp_shared_softmax(float* in_data,float* out_data,int rows,int cols)
{
    __shared__ float sdata[COLS_];
    int block_per_num = COLS_/BLOCKSIZE;
    int tid=threadIdx.x;
    int block_index=blockIdx.x;

    const float* data=in_data+block_index*cols;
    float* out=out_data+block_index*cols;

    float max_val=0.0f;
    for(int i=tid;i<cols;i+=BLOCKSIZE){
        sdata[i]=data[i];
        max_val=fmax(max_val,sdata[i]);
    }

    max_val = block_reduce_max<WARPSIZE,BLOCKSIZE>(max_val);

    float sum_val=0.0f;
    for(int i=tid;i<cols;i+=BLOCKSIZE){
        sdata[i] = exp(sdata[i]-max_val);
        sum_val+=sdata[i];
    }

    sum_val= block_reduce_sum<WARPSIZE,BLOCKSIZE>(sum_val);

    for(int i=tid;i<cols;i+=BLOCKSIZE){
        out[i]=sdata[i]/sum_val;
    }
}
```

#### transpose矩阵转置

```c++
//输入矩阵维度 n*m 输出矩阵的维度 m*n
// <n/32,m/32><32,32>
__global__ void cuda_transpose(float *in,float *out,int n,int m)
{
    int tid_x = blockIdx.x*blockDim.x+threadIdx.x;
    int tid_y = blockIdx.y*blockDim.y+threadIdx.y;
    int original = tid_y*m+tid_x;
    int next = tid_x*n+tid_y;
    out[next]=in[original];
}
```

![image-20240703135006672](/home/hp/code/HPC-Fight/HPC-Fight/image/123.png)

测试矩阵的大小是ROWS=2048，COLS=512; 

显存读分析：

1. Global Load刚刚好是，2048✖512✖4=4194304字节。
2. 且一个warp是32个线程，每个线程读取4字节，且每个线程是连续，因此合并为一个内存请求。Requests为：2048*512/32=32768
3. 一个内存请求连续的128字节，一个cache line，也就是一个sectors是32字节，对应32768*4=131072个sector

显存写分析：

1. 写回显存的时候，一个warp，访问的都是不同行，因此无法实现内存合并写，每个线程都要写一个sector，sector=2048✖512=1048576。
2. 总共写回的字节数有，sector=2048✖512*32=33554432字节，是读入的8倍数，只有八分之一的带宽用来写回数据了





通过share memory，让内存写，变成合并访问

```c++
//32 32
template<int BLOCK_SIZE_X,int BLOCK_SIZE_Y>
__global__ void cuda_transpose_share(float *in,float *out,int n,int m){

    __shared__ float sdata[BLOCK_SIZE_Y][BLOCK_SIZE_X];
    int x=threadIdx.x;
    int y=threadIdx.y;
    int tid_x = blockIdx.x*blockDim.x+threadIdx.x;
    int tid_y = blockIdx.y*blockDim.y+threadIdx.y;
    int original = tid_y*m+tid_x;


    sdata[y][x]=in[original];
    __syncthreads();

    tid_x = blockIdx.y*blockDim.y+threadIdx.x;
    tid_y = blockIdx.x*blockDim.x+threadIdx.y;
    int next=tid_y*n+tid_x;

    out[next]=sdata[x][y];
    __syncthreads();
}
```

![image-20240703145515771](/home/hp/code/HPC-Fight/HPC-Fight/image/image-20240703145515771.png)

在读的时候还和刚刚一样，一个warp的32个线程合并访问，一个request，读4个sector，128字节。把他写入共享内存里。

之后通过转换一些坐标，读的时候，读的是共享内存的一列，这样对应的时候就是转置矩阵的一行，可以达到合并访问。

但引入了共享内存之后，也会带来bank conflict。

在往共享内存写入的时候，刚刚好32个线程，对应32个bank。

单从共享内存读的时候，32个线程访问的是一列，刚刚好都访问同一个bank了，因此会出现大量的bank conflict。

一个warp会出现31个bank conflict，2048✖512/32✖31=1015808，和统计的1017217基本接近





通过padding减少，bankconflict

```c++
//32 32
template<int BLOCK_SIZE_X,int BLOCK_SIZE_Y>
__global__ void cuda_transpose_share(float *in,float *out,int n,int m){

    __shared__ float sdata[BLOCK_SIZE_Y][BLOCK_SIZE_X+1];
    int x=threadIdx.x;
    int y=threadIdx.y;
    int tid_x = blockIdx.x*blockDim.x+threadIdx.x;
    int tid_y = blockIdx.y*blockDim.y+threadIdx.y;
    int original = tid_y*m+tid_x;


    sdata[y][x]=in[original];
    __syncthreads();

    tid_x = blockIdx.y*blockDim.y+threadIdx.x;
    tid_y = blockIdx.x*blockDim.x+threadIdx.y;
    int next=tid_y*n+tid_x;

    out[next]=sdata[x][y];
    __syncthreads();
}
```

![image-20240703150402399](/home/hp/.config/Typora/typora-user-images/image-20240703150402399.png)

```c++
__shared__ float sdata[BLOCK_SIZE_Y][BLOCK_SIZE_X+1];
```

在声明共享内存的大小的时候，将最后一个维度+1，这样就可以避免读的时候bank conflict

![image-20240703151252159](/home/hp/code/HPC-Fight/HPC-Fight/image/image-20240703151252159.png)

如上图所示，一个warp32个线程，同时访问sdata的一列,即同时访问

```
s[0][0],s[1][0],s[2][0],s[3][0],---,s[31][0]
```

在padding后，实际上每个元素都在不同的bank上了，且刚刚好0-31号线程，分别访问0-31号bank。

但此时在，写的时候会有bank conflict

```
第一个warp 分别访问s[0][1],s[0][2],s[0][3],s[0][4],---,s[0][31]，分别对应bank0-bank31

第二个warp 分别访问s[1][1],s[1][2],s[1][3],s[1][4],---,s[1][31]
由于有padding，此时s[1][1]是bank 1，s[1][30]是bank[0] s[1][31]是bank[1],会有一个back conflict，从上图也可以看出来，却是会有一个重叠

2048✖512/32=1015808

```



#### 激活函数类

#### gemv

#### flash attention

### CUDA的Stream

### CUDA编程总结

### CUDA面试常见问题汇总

```
1. ### CUDA的线程组织结构

2. ### CUDA的存储体系结构，每一种存储的优缺点，该如何合理使用。

```
   全局内存：
   这是GPU中最大的内存，即我们常说的HBM内存，可以被所有块上的所有线程访问，当我们在GPU中初始化一个值而不指定其存储位置时，它会自动存储在全局内存中。然而，访问全局内存通常比其他内存类型慢，因此需要进行优化以避免性能下降，可以通过合并内存访问和使用共享内存来优化性能。

   共享内存：
   同一个Block内的线程可以通过共享内存共享数据。相比访问全局内存至少快个10倍，但共享内存的容量有限（通常为几十KB），无法被其他线程块访问。由于共享内存和缓存内存提供快速的访问速度，因此我们经常在计算过程中使用它们来存储数据。典型的方法是首先将所有数据从 CPU 复制到 GPU 并将其存储在全局内存中。然后，我们将数据分解成更小的部分（块）并将它们推送到共享内存中进行计算。计算完成后，结果将被推回全局内存。

   本地内存（Local Memory）
   每个线程都可以使用自己的本地内存，可以在其中存储临时变量。它具有最小的范围并且专用于每个单独的线程。


   GPU由多个SM组成，每个SM内有多个warp调度器。

   全局内存
   L2 cache
   L1 cache

   共享内存->物理上和L1 cache是在一起的，可以配置大小。一个block里共享，使用时需要注意同步。需要注意bank conflict
   寄存器->线程私有，自动分配
   local内存->寄存器溢出的时候会使用

   ```

   

3. ### GPU每一代的新特性有了解过吗？应该从哪里去了解详细信息？

   ```
   nvida官网，有一些架构的白皮书。
   CUDA tooklits里有对应架构的调优指南，这里讲得具体一些。

   https://www.nvidia.cn/technologies/
   Pascal架构    1050ti
   Volta架构
   Turing架构
   Ampere架构   RTX3080TI


   举例，比如在Ampere架构架构上提供了原生的Reduce操作，支持FP64，BFloat16的tensorcore


   ```

   

4. ### CUDA stream的概念，为什么要使用多个stream？

   ```
   CUDA Stream是指一堆异步的CUDA操作，它们按照主机（Host）代码确定的顺序在设备（Device）上执行。这些操作可以包括主机和设备之间的数据传输、内核（Kernel）启动以及其他由主机发起但由设备处理的命令。Stream允许操作在其中排队，并确保它们在先前的所有操作之后执行，从而提供了一种管理和组织异步操作的方式。

   当GPU在执行一个内核（Kernel）时，主机（Host）可能需要将数据从内存传输到GPU或从GPU传输回内存。通过使用多个Stream，可以在一个Stream中执行内核操作，同时在另一个Stream中执行数据传输操作。这样，数据传输和内核执行可以重叠进行，从而提高GPU的利用率。
   ```

   

5. ### GPU和CPU分别适合执行哪些程序？结合它们的硬件架构解释一下为什么它们有各自的优势。

6. ### 说明一下神经网络加速器与CPU、GPU的区别，他们各自有何优势？

7. ### 半精度浮点数FP16各个部分的具体位数，为什么要有半精度浮点数？

8. ### TensorCore的加速原理

9. ### MPI，OpenMP以及CUDA各自适用的加速场景。

10. ### RDMA相关问题。

11. ### 平时如何进行kernel的优化，会用到哪些工具？

12. ### CPU上哪些并行优化方法？

13. ### ARM相关的库有了解过吗？

14. ### PTX有了解过吗？

15. ### roofline模型有什么用？如何确定最优的BLOCK_SIZE。

16. ### GPU资源调度有哪些方法？

17. ### 稀疏矩阵的存储格式有哪些？稀疏矩阵的应用场景？稀疏矩阵计算与稠密矩阵计算有何不同？

18. ### 如何计算CPU指令的吞吐量和时延?

秋招，C++/HPC/AI Training & Inference，LLM/OP/MLSys

Nvidia/GPU/CUDA相关：

    描述一下SM的结构，在写kernel的时候共享内存大小和寄存器文件数量需要注意吗？
    共享内存和寄存器分别应该存放哪些数据，其用量与SM上活跃的线程块的关系。
    bank冲突是什么？描述具体结构，如何解决？
    说一下分支冲突，如果warp内有冲突，部分符合if条件，部分符合else条件，是否需要等待？
    项目中用过TensorCore吗？了解TensorCore的原理吗？
    为什么用float4向量来存取数据？有什么好处？
    为什么用双缓冲优化？了解cuda流和cuda graph吗？
    除了MPI，有知道现在用的更多的GPU通信库吗？
    在Nsight Computing中，经常关注的与内存相关的指标。有关注L1 Cache命中率吗？
    GPU指令集优化方面了解吗？有做过PTX相关的优化吗？
    GEMM是计算密集型还是访存密集型算子？
    知道cutlass中如何对GEMM进行优化的吗？


CPU相关：

    对Arm或者x86有什么了解？
    知道CPU的体系结构吗？说一下内存结构。
    设计多CPU系统的时候需要注意什么？如何保证缓存一致性？


机器学习/深度学习/训练推理相关：

    了解Transformer吗？底层是什么结构？cuda中如何优化？
    说一下你对大模型的理解。
    cuda中如何写Softmax？某个参数过大如何解决？
    Dropout和BatchNorm在训练和推理时有什么区别？
    说一下你了解的无监督学习算法。
    知道Faster Transformer吗？有了解如何实现的吗？
    Paged Attention有了解吗？
    知道TensorRT吗？部署过推理模型吗？


C++/数据结构/操作系统/设计模式相关：

    C++虚函数，使用场景，继承时，析构函数设定成虚函数。
    C++三大特性，动态多态和静态多态。
    多继承的问题，模版特化和偏特化。
    说一下线程和进程的区别，线程之间共享内容，进程和线程通信。
    静态库和动态库的原理，符号表，单例模式。
    快速排序，归并排序，堆排序时间复杂度一样，结合CPU的缓存访问来看，哪个效率最高？
    代码和文件较多时，如何定位内存错误的问题？


手撕/口述算法相关：

    CUDA Reduction或者向量相乘等可以转化为Reduction的Kernel。
    CUDA实现数组排序算法（双调排序）
    CUDA不考虑共享内存，只使用全局内存来做向量矩阵乘法，向量是行主序，矩阵乘向量和向量乘矩阵哪种访存和计算模式更好？说一说哪种用到了归约？
    有n个线程和n个元素，在logn时间内对n个元素进行排序。
    leetcode常见面试百题和魔改题。
   ```



# 推理框架

### 带显卡&&服务器端&&桌面设备：TensorRT

### 移动端&&嵌入式设备：ncnn

### 大模型推理：FastLLM、VLLM

### 推理框架总结&&常见问题汇总

# 模型量化

## float32 float16 bfloat16

![在这里插入图片描述](/home/hp/code/HPC-Fight/HPC-Fight/image/20210530155748732.png)

```
符号位 : 1代表负数， 0代表正数。
指数部分:8个比特位， 全0和全1有特殊用途，所以是00000001~11111110， 也就是1到254， 减去偏置127，指数部分最终范围为-126 ~127.
小数部分:c 小数部分， 23个比特位


对于FP16 与BF16
FP16：1位符号位 + 5位指数位 + 10位尾数位
BF16：1位符号位 + 8位指数位 + 7位尾数位


浮点数加法的精度问题：
一个很大的数加一个很小的数，会出现大数吃小数的问题，因为浮点数在做加法前，需要对阶，小阶对大阶。
小阶对大阶，就是指数部分小的数，要先变成与大的数指数部分一样，这就会导致，小数部分会右移,就会有对应的精度丢失。
比如

对于FP16与BF16的区别：
BF16指数位多，表示整数数值范围大(2为底的指数)；尾数位少，所以尾数精度较低。
FP16指数位少，表示整数数值范围小；尾数位多，所以尾数精度较高。
因为BF16比FP16能表示的数值范围更大，所以在计算时不容易出现上溢或下溢的问题。在混合精度训练时，从FP32转换为FP16时，很容易出现溢出，因为表示不了数值范围；而从FP32很容易转换为BF16，因为BF16具有与 FP32相同的指数位数，但其损失了精度。
```

### 量化基本知识

```
什么是量化？量化是把一个浮点数量化到一个定点数（比如float16到int8 比如float16到int4）


量化基本公式


对称量化（以int8为例）
1.计算scale
scale=abs_max/128;  scale是一个浮点数

2.利用scale，执行数据量化
x=round(x/scale)   此时x是一个整数了，并且范围在-127～128

3.反量化
x=x*scale 此时x是一个浮点数了


非对称量化
1.计算scale和z
scale = (xmax-xmin)/255
z = 128-round(xmax/scale)

2.利用scale和z，执行数据量化
x=round(r/scale+z)

3.反量化
x=(x-z)*scale



区别：
对称量化仅需要确定一个缩放因子，无需确定零点，因此计算更为简单。更适用于权重值的量化。对于某些特殊情况（如全非负值的数据，relu的激活值），对称量化可能不是最佳选择。

由于能够更精确地映射原始数据的分布，非对称量化通常能减少量化过程中的信息损失和误差。相比于对称量化，非对称量化需要额外的计算来确定零点（zero point）和缩放因子（scale），因此具有较大的计算开销。适用于激活值（即中间输出值）的量化，因为激活值的分布通常是不对称的。
```

### 量化加速原理

1.因为模型推理的时候大部分算子都是memory bound。数据位宽减小，那说明可以一次性处理多个数据，吞吐量提高。

2.基本上所有计算设备，如nvdia的显卡，int8的计算能力都比浮点数的高

### 大模型量化

#### LLM.int8()

```
背景：
1.量化的粒度更细了，从per_tensor和per_channel到了，到单独量化每一行或者每一列。对于矩阵A*B来说，量化A的每一行和B的每一列
2.对离群值的处理，把离群值单独拿出来做fp16的计算
	比如： 
	0.1 0.2 0.1 10 0.3      0.1 0.1 0.1 0.1
	0.2 0.3 0.1 12 0.1		0.2 0.2 0.2 0.2
							0.3 0.3 0.3 0.3
							0.4 0.4 0.4 0.4
							0.5 0.5 0.5 0.5
	
	
							
一个 2✖5的矩阵与5✖4的矩阵相乘 2✖4

对激活值分解
0.1 0.2 0.1  0.3  	0.1 0.1 0.1 0.1     10		0.4 0.4 0.4 0.4
0.2 0.3 0.1  0.1  	0.2 0.2 0.2 0.2		12
					0.3 0.3 0.3 0.3
					0.5 0.5 0.5 0.5
分解为 2✖4的矩阵与4✖2的矩阵相乘 2✖1的矩阵与1✖4的矩阵相乘
其中2✖4的矩阵与4✖2的矩阵相乘用INT8的乘法
2✖1的矩阵与1✖4的矩阵相乘做fp16的乘法
```



#### SmoothQuant

![image-20240623161907791](/home/hp/code/HPC-Fight/HPC-Fight/image/image-20240623161907791.png)

```
2.对离群值的处理，把离群值缩放倍数，把缩放的倍数乘到权重上去
```



#### AWQ（W4A16，W8A16）

```
```







### 量化常见问题总结



```
1、量化的基本公式:同上

2、量化的误差来源有哪些

    量化级数有限：由于可用的离散量化水平有限，无法精确表示所有连续值。
    舍入操作：在将连续值映射到最近的量化水平时产生的。
    非均匀量化：不同区间内的量化间隔不一致可能导致误差。
    计算过程中的累积误差：多次量化操作后误差可能累积。
    量化参数选择不当：如量化的位数、量化区间等设置不合理。


3、既然有误差，那为何某些业务对误差不敏感，有的又非常敏感
	
    应用场景对精度要求较低，如图像压缩、音频传输等。
    后续处理可以容忍或修正这些误差。
    实时性或资源节省需求高于精度。

而有些业务则非常敏感，例如：

    医疗影像分析、金融预测等要求极高精确度的领域。
    模型的决策边界接近，轻微的量化误差可能导致分类错误。

4、量化信息是插入tensor还是op，或者是两者都要
	量化信息通常既插入到tensor（权重和激活值）中也应用于op（操作），确保整个模型的前向传播过程中数据保持量化状态。
	
5、ptq量化的基本流程
	
    收集校准数据：使用一小部分代表性数据集。
    推理校准：在浮点模型上运行校准数据，收集权重和激活的统计信息。
    确定量化参数：基于统计信息确定量化尺度和零点。
    应用量化：使用这些参数将模型的权重和激活值量化为低精度格式。

6、ptq和qat的简单区别

    PTQ在模型训练完成后进行，不需要额外训练，快速但可能牺牲一些精度。
    QAT在训练过程中引入量化操作（使用fake quant），允许模型适应量化带来的误差，通常能获得更好的精度，但耗时较长。

7、常说的per tensor和per channel，对于conv2d的weight来说具体有什么区别
	
    Per Tensor：整个权重张量共享相同的量化参数（scale和zero point）。
    Per Channel：每个输出通道（filter）都有独立的量化参数，提高了量化精度，但增加了计算和存储开销。


8、量化里常说的fake quant大概是在干什么
	在训练期间模拟量化操作，使得模型能够在未真正量化的情况下学习量化带来的影响，帮助模型适应量化环境。
	
9、对于qat来说，fake quant在训练和推理时有什么区别
	训练时：fake quant作为模型的一部分，动态调整权重和激活值，帮助模型学习量化条件下的最优参数。
	推理时：若模型已经过充分的QAT，fake quant可能被实际的量化操作替代，以实现真正的低精度推理
	
10、对称非对称，有无符号等量化选择，对于conv2d的3个输入来说一般各自采用哪种组合
	
    特征图（输入/激活）：通常采用非对称量化，有符号。
    权重：根据情况选择对，通常非对称更常见，有符号。

11、requant的基本计算逻辑和作用

12、混合精度的基本计算逻辑
	混合精度量化是指在模型的不同部分使用不同位宽的量化，以平衡精度和效率。例如，权重可能用8位，而激活值用4位。关键在于合理分配位宽，确保关键层或操作保持较高精度
13、量化中有哪些op通常需要特殊处理
	分支操作（如if条件）、循环结构、非线性函数（如ReLU）、归一化层（如BN）、池化层等，这些可能需要定制的量化策略以保持模型性能。
14、对于conv2d来说，multiplier，shift如何推理出来的

15、对于conv2d来说，采用multiplier，shift计算时，对bias的scale有特殊要求吗

16、对称量化时我们统计出来的浮点范围，为何要限制min≤0，max≥0

17、常见的阈值搜索方法

18、8bit量化带符号时，q_min选-128和-127的有区别吗

19、为什么有的模型会出现中间量化误差大，后续量化误差又减少的情况

20、余弦度量在衡量量化误差上有什么优缺点  帮我回答一下这个20个问题
```



# 大模型推理加速

### flash attention

### page attention

### kv cache

### 大模型量化&&前沿的量化论文

# 手撕代码

### leetcode

### c++的一些设计模式

#### 生产者消费者模型

```c++
#include<algorithm>
#include<thread>
#include<mutex>
#include<condition_variable>
#include<queue>
#include<iostream>
#include<chrono>

using namespace std;

static int index = 0;
class Prodeuce_consumer {
	
public:	
	Prodeuce_consumer() {
		max_size = 10;
	}

	Prodeuce_consumer(int size) {
		max_size = size;
	}

	Prodeuce_consumer(const Prodeuce_consumer& p1) {
		max_size = p1.max_size;
	}

	Prodeuce_consumer& operator =(const Prodeuce_consumer& p1) {
		if (&p1 == this) return *this;
		Prodeuce_consumer p = Prodeuce_consumer(p1.max_size);
		return p;
	}

	virtual ~Prodeuce_consumer() {

	}

	void run() {
		thread t1(&Prodeuce_consumer::procuder,this);
		thread t2(&Prodeuce_consumer::consumer, this);
		thread t3(&Prodeuce_consumer::consumer, this);
		thread t4(&Prodeuce_consumer::consumer, this);

		t1.join();
		t2.join();
		t3.join();
		t4.join();
	}


	void procuder() {
			
		while (1) {
			
			this_thread::sleep_for(chrono::milliseconds(100));
			{
				unique_lock<mutex> ul(mu);
				cond.wait(ul, [&]() {
					return que.size() < max_size;
					});
				que.push(index++);
				cout << "producer is " << index << "  ";
				cout << "que size is " << que.size() << endl;
			}
			


		}

	}


	void consumer() {

			
		while (1) {
 
			{
				lock_guard<mutex> l(mu);
				if (!que.empty()) {
					int cur = que.front();
					que.pop();
					cout <<"ID IS   "<<this_thread::get_id()<< "   consumer run " << cur << endl;
					cond.notify_all();
				}
			}
			this_thread::sleep_for(chrono::milliseconds(500));
			
		}


	}

private:
	int max_size;
	queue<int> que;
	mutex mu;
	condition_variable cond;

};




int main()
{
	Prodeuce_consumer p1;
	p1.run();
}

```

#### 线程安全的单例模式

```c++
class Test {

	Test& get_instance() {
		static Test t1;
		return t1;
	}

private:
	Test() {};
	Test(const Test& t) = delete;
	Test& operator=(const Test& t) = delete;
};


template <class T>
class Singleton
{
private:
    Singleton() = default;
    ~Singleton() = default;
    Singleton(const Singleton&)=delete;
    Singleton& operator=(const Singleton&)=delete;
 
public:
    static T* instance()
    {
        std::call_once(_flag, [&](){
            _instance = new T();
        });
        return _instance;
    }
 
private:
    static T* _instance;
    static std::once_flag _flag;
};
 

```



#### 智能指针

```c++



//share_ptr
template<class T>
class SmartPtr{
public:
	SmartPtr(T* ptr = NULL): _ptr(ptr), _pcount(new int(1)) {} //构造函数
	SmartPtr(const SmartPtr& s): _ptr(s.ptr), _pcount(s._pcount){  //拷贝构造函数
		*(_pcount)++; //用指针进行count操作能够方便控制不同智能指针对象的计数值
	}
	SmartPtr<T>& operator=(const SmartPtr& s){  //重载 = ，赋值函数
		if(this != &s){ //检测自我赋值
			if(--(*(this->_pcount)) == 0){
				delete this->_ptr;
				delete this->_pcount;
			}
			_ptr = s._ptr;
			_pcount = s._pcount;
			*(_pcount)++;
		}
		return *this;
	}
	T& operator*(){
		return *(this->_ptr);
	}
	T* operator->(){
		return this->_ptr;
	}
	~SmartPtr(){ //析构函数要进行判定，count为0才会delete，delete之后避免野指针要赋值nullptr
		--(*(this->_pcount));
		if(this->_pcount == 0){
			delete _ptr;
			_ptr = nullptr;
			delete _pcount;
			_pcount = nullptr;
		}
	}
private:
	T* _ptr;
	int* _pcount;
};

template <typename T> 
class unique_ptr {
private:
  T *ptr_resource = nullptr;

public:
  // explicit构造函数是用来防止隐式转换, 即不允许写成unique_ptr<T> tempPtr = T;
  // std::move是将对象的状态或者所有权从一个对象转移到另一个对象，只是转移，没有内存的搬迁或者内存拷贝所以可以提高利用效率,改善性能.
  // move之后，raw_resource内部的资源将不能再被raw_resource使用
  explicit unique_ptr(T *raw_resource) noexcept
      : ptr_resource(std::move(raw_resource)) {}
  unique_ptr(std::nullptr_t) : ptr_resource(nullptr) {}

  unique_ptr() noexcept : ptr_resource(nullptr) {}

  // 析构时, 释放托管的对象资源
  ~unique_ptr() noexcept { delete ptr_resource; }

    
  unique_ptr(const unique_ptr<T> &) noexcept = delete;
  unique_ptr &operator=(const unique_ptr &) noexcept = delete;

public:
  //&& 是右值引用，见https://zhuanlan.zhihu.com/p/107445960
  // 允许移动语义。虽然无法复制unique_ptr，但可以安全地移动。
  // 例子：unique_ptr<Test> tPtr3(std::move(tPtr1));
  unique_ptr(unique_ptr &&move) noexcept {
    std::cout << "construct for unique_ptr&&" << std::endl;
    move.swap(*this);
  }
  // ptr = std::move(resource)
  unique_ptr &operator=(unique_ptr &&move) noexcept {
    std::cout << "operator= for unique_ptr&&" << std::endl;
    move.swap(*this);
    return *this;
  }


public:
  // overloaded operators
  T *operator->() const noexcept { return this->ptr_resource; }
  T &operator*() const noexcept { return *this->ptr_resource; }
  // 额外说明noexcept
  // noexcept C++11关键字,
  // 告诉编译器，函数中不会发生异常,有利于编译器对程序做更多的优化
  // C++中的异常处理是在运行时而不是编译时检测的。为了实现运行时检测，编译器创建额外的代码，然而这会妨碍程序优化
};

```





### cuda

#### reduce

```c++
//分配一个warp处理一个block里的数据
template<int WARPSIZE>
__device__ __forceinline__ float warp_reduce_add(float val)
{
    for(int mask=WARPSIZE>>1;mask>=1;mask>>=1){
        val+=__shfl_xor_sync(0xffffffff,val,mask);
    }
}


template<int warpsize>
__device__ warp_reduce_add(float val)
{
    for(int mask=warpsize>>1;mask>=1;mask>>=1){
        val+=__shfl_xor_sync(0xffffffff,val,mask);
    }
    return val;
}

template<int warpsize>
__device__ warp_reduce_max(float val)
{
    for(int mask=warpsize>>1;mask>=1;mask>>=1){
        val=fmax(__shfl_xor_sync(0xffffffff,val,mask),val);
    }
    return val;
}


template<int warpsize,int blocksize>
__device__ block_reduce_sum(float val)
{

    __shared__ float sdata[blocksize/warpsize];

    int tid=threadIdx.x;
    int warp_index=tid/warpsize;
    int warp_thread=tid&(warpsize-1);
    int warp_num=blocksize/warpsize;

    val=warp_reduce_add<warpsize>(val);

    if(warp_thread==0) sdata[warp_index]=val;
    __sync_threads();

    val = (warp_thread < warp_num)?sdata[warp_thread]:0;

    val=warp_reduce_add<warpsize>(val);

    return val;

}

template<int warpsize,int blocksize>
__device__ block_reduce_max(float val)
{

    __shared__ float sdata[blocksize/warpsize];

    int tid=threadIdx.x;
    int warp_index=tid/warpsize;
    int warp_thread=tid&(warpsize-1);
    int warp_num=blocksize/warpsize;

    val=warp_reduce_max<warpsize>(val);

    if(warp_thread==0) sdata[warp_index]=val;
    __sync_threads();

    val = (warp_thread < warp_num)?sdata[warp_thread]:-1000.0;

    val=warp_reduce_max<warpsize>(val);

    return val;

}
    return val;
}
```

softmax

```c++
template<int WARPSIZE,int BLCOKSIZE,int COLS>
__device__ void warp_softmax(float input,float output,int rows,int cols)
{

    constexpr int nums=COLS/WARPSIZE;
    __shared__ float sdata[nums];

    int tid=threadIdx.x;
    int row_index = blockIdx.x;

    float* row_ptr = input+row_index*cols;
    float* out_prt = output+row_index*cols;

    float val_max=-10000f;
    for(int i=0;i<num;i++){
        sdata[i]=input[tid+i*WARPSIZE];
        val_max=fmax(sdata[i],val_max);
    }

    val_max = warp_reduce_max<WARPSIZE>(val_max);

    float val_sum=0.0f;
    for(int i=0;i<num;i++){
        sdata[i]=exp(sdata[i]-val_max)
        val_sum=val_sum+sdata[i];
    }
    val_sum = warp_reduce_sum<WARPSIZE>(val_sum);


    for(int i=0;i<num;i++){
        out_prt[tid+i*WARPSIZE]]=data[i]/val_sum;
    }

}
```





### 手撕一些算子（用c++或者pytorch）

#### c++计算IOU

```c++
struct Bbox{
	int x1;
    int x2;
    int y1;
    int y2;
}

float iou(const& Bbox bbox1,const& Bbox bbox2){
    
    int min_x=max(bbox1.x1,bbox2.x1);  //注意求左上角，是用max
    int min_y=max(bbox1.y1,bbox2.y1);
    
    int max_x=min(bbox1.x2,bbox2.x2);
    int max_y=min(bbox1.y2,bbox2.y2);
    
    int common=(max_x-min_x+1)*(max_y-min_y+1);
    
    
    int bbox1_size=(bbox1.x2-bbox1.x1+1)*(bbox1.y2-bbox1.y1+1);
    int bbox2_size=(bbox2.x2-bbox2.x1+1)*(bbox2.y2-bbox2.y1+1);
    
    return common/(bbox2_size+bbox1_size-common);
    
    
}

```

#### NMS

```c++
基本流程
1.所有的框根据置信度排序
2.遍历这些框，对每个框与已经被选中的框比较，如果这些框与以及被选中的框IOU过大，且属于统一类别则抛弃这个框
3.返回所有被选中的框


#include <iostream>
#include <vector>
#include <algorithm>

struct Box {
    int x1, y1, x2, y2;
};

// 计算两个边界框的交并比
float iou(const Box& box1, const Box& box2) {
    int x1 = std::max(box1.x1, box2.x1);
    int y1 = std::max(box1.y1, box2.y1);
    int x2 = std::min(box1.x2, box2.x2);
    int y2 = std::min(box1.y2, box2.y2);

    int width = std::max(0, x2 - x1 + 1);
    int height = std::max(0, y2 - y1 + 1);

    int intersection = width * height;

    int area1 = (box1.x2 - box1.x1 + 1) * (box1.y2 - box1.y1 + 1);
    int area2 = (box2.x2 - box2.x1 + 1) * (box2.y2 - box2.y1 + 1);

    float iou = static_cast<float>(intersection) / (area1 + area2 - intersection);

    return iou;
}

// NMS算法实现
std::vector<int> nms(const std::vector<Box>& boxes, const std::vector<float>& scores, float threshold) {
    std::vector<int> order(scores.size());
    for (int i = 0; i < scores.size(); i++) {
        order[i] = i;
    }

    // 按照得分降序排列边界框的索引
    std::sort(order.begin(), order.end(), [&](int a, int b) { return scores[a] > scores[b]; });

    std::vector<int> keep;  // 用于存储保留的边界框索引
    while (!order.empty()) {
        int i = order[0];  // 选择得分最高的边界框
        keep.push_back(i);  // 将该边界框的索引添加到保留列表中

        std::vector<float> ious;  // 存储当前边界框与其他边界框的交并比
        for (int t = 1; t < order.size(); t++) {
            ious.push_back(iou(boxes[i], boxes[order[t]]));  // 计算当前边界框与其他边界框的交并比
        }

        std::vector<int> inds;  // 存储交并比小于阈值的边界框的索引
        for (int t = 0; t < ious.size(); t++) {
            if (ious[t] <= threshold) {
                inds.push_back(t);  // 将交并比小于阈值的边界框的索引添加到列表中
            }
        }

        std::vector<int> new_order;  // 存储更新后的order数组
        for (int t = 0; t < inds.size(); t++) {
            new_order.push_back(order[inds[t] + 1]);  // 更新order数组，去除保留的边界框的索引
        }
        order = new_order;
    }

    return keep;  // 返回保留的边界框索引
}

int main() {
    // 示例输入
    std::vector<Box> boxes = {{50, 50, 100, 100}, {60, 60, 120, 120}, {70, 70, 130, 130}, {80, 80, 140, 140}};
    std::vector<float> scores = {0.9, 0.75, 0.8, 0.95};
    float threshold = 0.5;

    // 调用NMS算法
    std::vector<int> keep = nms(boxes, scores, threshold);

    // 打印保留的边界框索引
    std::cout << "保留的边界框索引：";
    for (int i = 0; i < keep.size(); i++) {
        std::cout << keep[i] << " ";
    }
    std::cout << std::endl;

    return 0;
}


static void nms_sorted_bboxes(const std::vector<Object>& faceobjects, std::vector<int>& picked, float nms_threshold, bool agnostic = false)
{
    picked.clear();

    const int n = faceobjects.size();

    std::vector<float> areas(n);
    for (int i = 0; i < n; i++)
    {
        areas[i] = faceobjects[i].rect.area();
    }

    for (int i = 0; i < n; i++)
    {
        const Object& a = faceobjects[i];

        int keep = 1;
        for (int j = 0; j < (int)picked.size(); j++)
        {
            const Object& b = faceobjects[picked[j]];

            if (!agnostic && a.label != b.label)
                continue;

            // intersection over union
            float inter_area = intersection_area(a, b);
            float union_area = areas[i] + areas[picked[j]] - inter_area;
            // float IoU = inter_area / union_area
            if (inter_area / union_area > nms_threshold)
                keep = 0;
        }

        if (keep)
            picked.push_back(i);
    }
}

```



# 面试经验

```

第一个项目主要是实验室的项目，是一个在无人驾驶设备上的导航算法研究，分为定位、感知、规划和控制这些模块。我是负责环境感知算法的设计部署和应用。
主要有这三方面的工作：
第一个是算法的设计，用的是多目标检测与跟踪算法和深度相机来做前方目标的识别和定位。
第二个是算法的加速，这里就包含模型量化加速，cuda加速图像预处理，和并行加速
第三个是与其他模型联合做的高级功能，主要是一些避障、倒车、停车的这些功能。

我先讲一下算法的流程，以及每部分是在什么设备上跑，以及耗时大概是多少。
算法分成，三个部分：
第一部分，相机图像的获取，这里用的相机是因特尔的深度相机D455i，是在CPU上跑，30FPS
第二部分，图像预处理和目标检测。图像预处理的化主要是BGR到（RGB，归一化，Resize），这三个部分的化如果是用opencv的函数实现的化，大概10ms，但其实这三部可以统一位一个彷射变化，利用旋转平移矩阵取计算，这样耗时大概是1-2ms，目标检测在Tensorrt int8量化后大概耗时后是80ms。所以其实这一部分总耗时大概就是80ms
第三部分，目标跟踪部分，这是一个检测后跟踪的算法，是用卡尔曼滤波做的，这在CPU上跑，耗时2ms。

这就是算法的三个部分，然后我做了并行化的加速，一共是用了三个线程和两个工作队列，第一个线程处理摄像机的图像获取，把图像放到第一个工作队列李。第二个线程是图像预处理+目标检测，把第一个工作队列里的图像拿出来做处理完后，放进第二个工作对列里。另外这里也用了tensort的多个context推理，可以并行的处理多个图像，增加整个算法的吞吐量和提高GPU的利用率。最后一个线程就是，把第二个工作队列里的图像拿出，做跟踪。



第二个项目，是我自己写的推理框架，虽然现在有许多大的开源的推理框架，但是我写的这个也有一些自己的特色。主要是有两方面的工作：
第一就是，因为写的是一个完整的框架，所以需要从全局的角度，去思考整个框架的架构，包括一些类的抽象，计算图的构建，以及内存管理这些。以及用一些设计模式提高代码的可扩展性和可读性。
第二就是，算子的实现，算子的实现有CPU版本和GPU版本，CPU的版本计算结果会与pytorch的算子结果对齐，GPU算子会与CPU的结果对齐，每个算子也会有单元测试进行结果的校验。同时在GPU的算子，比如softmax，reduce算子上也有一些进一步的优化。


模型的导入导出，为什么选用PNNX？以及PNNX与其他导出模型的优势？
pnnx与onnx相比具有的优点

1.onnx是google protobuf写的一个库，只能支持导出最大2GB大小的模型，但现实的大模型随随便便就大于2GB的，pnnx就没有这个限制
2.onnx如果遇到不支持的算子的话，模型就无法正常导出。但pnnx可以导出所有的算子，对于不支持的算子只要在后端的推理框架实现就可以
3.最后一点也是最终要的一点，就是算子的细粒度是不一样的。pnnx算子的粒度和pytroch是一致的，但onnx的算子的粒度是很小的。以layernorm为例，onnx会把他拆成三个算子，但pnnx直接导出就是一个layernorm。在实际的推理过程中，算子的融合是一个非常有效但又非常难做的事。所一直接使用pnnx导出与pytroch对齐的算子，可以更好的在后端做优化。


大概可以递归8*1024*1024 / 每个函数耗费的栈空间，大概可以递归1-2w次数
以qwen2，72B为例子，算它80个transformer block，一个transforemr也就10多个算子，也就800多层，基本不会有栈溢出的风险
EasyNN是动态图，动态图有两个优势，一个是图的生成写起来很方便，直接使用递归10几行就可以完成，第二个就是可以提取到中间层的结果，同时在有分支的情况下也可以减少计算量

内存管理
1.Mat的管理是在内部封装了引用计数。
2.对模型的权重，以及算子推理做了分离。就是一个Net类是存储的是计算图的信息、模型各个算子的权重。另一个类里面，封装的是计算图推理过程中需要用到的输入输出，以及实际的推理逻辑。以卷积为例，卷积的权重是放到Net里面，卷积的输入输出是放到另外一个类里。然后因为他们是有耦合的，所以这里实际上通过友元来实现他们之间成员的相互访问。然后这么做的好处是，可以实现一份权重，多个线程推理，达到并行化的效果。这么做的话，如果想同时推理多个图片，那么他们共用的是同一份模型权重。
3.另外，在模型实际推理过程中也做了一些细致化的内存管理。总体上来说，是使用了一个内存池来实现内存的复用，对于中间某个算子的推理输入，在使用完后，并不会立刻释放，而是会在内存池中回收。第二点是，对于激活函数类的算子，可以实现就地推理，也可以减少内存占用。


设计模式
1.测试框架是一个单列模式，便于管理
2.算子之间的隔离，一个纯虚类，layer类，然后各个算子的具体去继承即可。另外使用工厂模式实现了代码的抽象


第三个项目
硬件参数：Orangepi 5
RK3588S 4核-Cortex-A76 4核-Cortex-A55 ARMV8架构，NPU 6 TOPs的算力
```





